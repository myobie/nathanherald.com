<!DOCTYPE html>
<html>
  <head lang="en-us">
    <meta charset="UTF-8">
    <title>
      I'm Nathan Herald ‚Üí This is not my take on AI
    </title>
    <script>
      if ((new URL(window.location.href)).host === 'myobie.com') { window.location.assign('https://nathanherald.com') }
    </script>
    <link href="https://cloud.typography.com/6836312/761366/css/fonts.css" rel="stylesheet" type="text/css">
    <link href="/styles.css" rel="stylesheet" type="text/css">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta content="I'm Nathan Herald ‚Üí This is not my take on AI" name="title">
    <meta content="" name="description">
    <meta content="This is not my take on AI" property="og:title">
    <meta content="website" property="og:type">
    <meta content="" property="og:description">
    <meta content="/og.png" property="og:image">
    <meta content="I'm Nathan Herald" property="og:site_name">
    <link href="/rss.xml" rel="alternate" title="Feed of all the posts on nathanherald.com" type="application/rss+xml">
  </head>
  <body>
    <header class="section-header">
      <div class="section-nav">
        <h1 class="home-link">
          <a class="never-underline" data-nospan="" href="/"><abbr title="Hello">üëã</abbr></a>
          <a href="/">I'm Nathan</a>
        </h1>
        <nav>
          <p>
            Find more in the <a href="/posts/">archive of all the posts on this site</a> or
            <a href="/rss.xml">subscribe with RSS</a>.
          </p>
        </nav>
      </div>
    </header>
    <main class="single">
      <article>
        <header>
          <h1>
            This is not my take on AI
          </h1>
        </header>
        <div class="content">
<p><em>The world doesn‚Äôt need another take.</em></p>
<p><em>TL;DR: I‚Äôve concluded that AI is coming and it‚Äôs important I
understand it and I am in control of my data, of my context. This is why
I am personally working to enable local AI workflows on phones and
laptops. I‚Äôll keep this page updated as I learn more.</em></p>
<hr />
<p><details-controls></details-controls></p>
<hr />
<p>AI tools and companies are progressing fast and I have a lot of
questions that I haven‚Äôt found easy answers to. <strong>So, I‚Äôve taken
some time to research, use AI for real work, and read a lot of takes on
AI. I‚Äôm collecting what I‚Äôve learned here.</strong> I plan to keep this
page semi-up-to-date over time as I learn more. I don‚Äôt want to make a
lot of blog posts about AI, instead I‚Äôll just have this page here as a
living document. I‚Äôll try to pull my ‚Äúbig takeaways‚Äù up here to the
top.</p>
<h2
id="big-takeway-1-ai-is-here-and-its-best-for-me-to-understand-it">Big
Takeway #1: AI is here and it‚Äôs best for me to understand it</h2>
<blockquote>
<iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen frameborder="0" height="315" src= "https://www.youtube-nocookie.com/embed/XAPfNPIvWkM" width="560"></iframe>

<p>Rage Against The Machine - Know Your Enemy Clip (Live At Finsbury
Park)</p>
</blockquote>
<p>This stuff is probably coming for you too. Those automated phone
systems where you ‚Äúhit 3 for billing‚Äù are terrible and annoying. They
are not <em>better</em> than just speaking to a human. And yet, those
are forced upon us to save costs, to reduce the number of jobs. AI seems
like that times 100: it will reduce costs so much that it will be used
whether it‚Äôs good or not.</p>
<p>And, if there are productivity gains to be had, and I think there
are, then we should own the means to run the programs that deliver them.
I‚Äôm building <a href="https://new.space/app">new.space</a> where you can
make sense of all your tabs, bookmarks, files, and notes in a private,
collaborative space using AI as you choose, you are in control. That is
one possible way to do own our data and context going forward: build
products that respect privacy and user control, letting us choose where
our data goes and when.</p>
<h2
id="big-takeaway-2-for-me-always-work-on-code-like-an-open-source-project">Big
takeaway #2 for me: Always work on code like an open source project</h2>
<p>I‚Äôve always tried to work as close to the open source model as
possible, and now I think that is even more important. In an open
project you get suggested code changes from people you‚Äôve never met or
heard of, their code is of dubious quality, and you have to really vet
and understand their code before accepting it into the project. Even
those you‚Äôve added as contributors can make mistakes or their accounts
can get hacked.</p>
<p>Code originating from generative AI must be seen as a suspicious
contribution as well.</p>
<p>What‚Äôs great is we already have tools to handle this. We have pull
request reviews, CI, multi-approval requirements before merging,
sandboxes or staging environments, etc. All of these things are made to
protect us from ourselves, and they will all help protect us from AI
tools as well.</p>
<p>TK I‚Äôd love to expand on this more soon.</p>
<h2 id="links-i-havent-had-a-chance-to-go-through-yet">Links I haven‚Äôt
had a chance to go through yet</h2>
<ul>
<li><a
href="https://malwaretech.com/2025/08/every-reason-why-i-hate-ai.html">https://malwaretech.com/2025/08/every-reason-why-i-hate-ai.html</a>
(via <a
href="https://adactio.com/links/22087">https://adactio.com/links/22087</a>)</li>
<li><a href="https://anthonymoser.github.io/writing/ai/haterdom/2025/08/26/i-am-an-ai-hater.html">https://anthonymoser.github.io/writing/ai/haterdom/2025/08/26/i-am-an-ai-hater.html</a></li>
<li><a href="https://mastodon.social/@searls/115072539129871055">https://mastodon.social/@searls/115072539129871055</a></li>
<li><a href="https://desunit.com/blog/in-the-long-run-llms-make-us-dumber/">https://desunit.com/blog/in-the-long-run-llms-make-us-dumber/</a></li>
<li><a href="https://mas.to/@carnage4life/115059290859727270">https://mas.to/@carnage4life/115059290859727270</a></li>
<li><a href="https://steipete.me/posts/just-one-more-prompt">https://steipete.me/posts/just-one-more-prompt</a></li>
<li><a href="https://mastodon.social/@mcc/115176228086016550">https://mastodon.social/@mcc/115176228086016550</a></li>
<li><a href="https://nelson.cloud/local-text-summarization-with-ollama-and-python-is-just-string-manipulation/">https://nelson.cloud/local-text-summarization-with-ollama-and-python-is-just-string-manipulation/</a></li>
</ul>
<h2 id="the-internet-is-full-of-confusing-takes">The internet is full of
confusing takes</h2>
<p>Some of the smartest people I know are anti-AI and refuse to
knowingly use it. Some of the other smartest people I know are using AI
everyday, and say everyone else should too. I‚Äôve heard some say they‚Äôve
been ‚ÄúAI pilled‚Äù (both in a positive and negative way). Some say there
is no ethical way to use AI. Some say AI is mistaken so often to be
useless. Others say it‚Äôs correct so often that they don‚Äôt need as many
employees/coworkers anymore to do their work.</p>
<p>In this current moment, if someone tells you what AI can definitely
do or what it can definitely not do without a clear demo that you can
run yourself, then you can‚Äôt believe them. Companies are saying it can
do more than it probably can. Skeptics or those against AI are spreading
misinformation that it cannot do things which it can objectively do.
Both are problematic.</p>
<p>RE:</p>
<ul>
<li><a href="https://fly.io/blog/youre-all-nuts/">My AI Skeptic Friends
Are All Nuts</a></li>
<li><a
href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/?utm_source=chatgpt.com">Contra
Ptacek's Terrible Article On AI</a></li>
<li><a href="https://mastodon.social/@jcoglan/114624176663492584">if you
are going to write an article making claims like AI can break down
problems, it can reason, it can refactor, it can help you learn, it is
genuinely capable at the task of producing software, you actually need
to provide evidence at this point</a></li>
</ul>
<h2 id="ethical-concerns">Ethical concerns</h2>
<p>Two people I respect:</p>
<blockquote>
<p>‚Ä¶Ethical concerns front and center. First thing. Let‚Äôs get this out
of the way and then see if thre is anything left worth talking
about‚Ä¶</p>
<p><a
href="https://narrativ.es/@janl/114566975034056419">https://narrativ.es/@janl/114566975034056419</a></p>
</blockquote>
<p>and</p>
<blockquote>
<p>‚Ä¶If you refuse to use these tools on ethical grounds or simply don't
bother to keep up with them, I fear your employment prospects are likely
to suffer in the short and medium term.</p>
<p><a
href="https://mastodon.social/@searls/114565915634957316">https://mastodon.social/@searls/114565915634957316</a></p>
</blockquote>
<p><em>So here are answers to my own ethical questions, front and
center. If you think of more, please hit me up <a
href="https://indieweb.social/@myobie">on mastodon</a>, I‚Äôd love to
learn/research more.</em></p>
<details>
<summary>Are all AI tools trained on stolen content?</summary>

<p>No. And this surprised me.</p>
<p>Firefly is trained only on licensed content by Adobe. This seems like
a great decision for them, especially from a quality control
perspective.</p>
<p><a
href="https://www.adobe.com/ai/overview/firefly/gen-ai-approach.html">Our
approach to generative AI with Adobe Firefly</a></p>
<blockquote>
<p>We only train Adobe Firefly on content where we have permission to do
so.</p>
</blockquote>
<p>Phi4 claims to be trained on high quality data like licensed books
and academic sources. This is a very good, tool call capable model, so
this opens up a ton of local AI use cases where you use your own energy
to do AI tasks with a more ethically trained model.</p>
<p><a
href="https://deepinfra.com/microsoft/phi-4?utm_source=chatgpt.com">phi-4
on Deepinfra</a></p>
<blockquote>
<p>Phi-4 is a model built upon a blend of synthetic datasets, data from
filtered public domain websites, and acquired academic books and Q&amp;A
datasets. The goal of this approach was to ensure that small capable
models were trained with data focused on high quality and advanced
reasoning.</p>
</blockquote>
<p>So it seems very possible to build SMLs and maybe even LLMs in an
ethical way with enough effort and will.</p>
<p>However, all the ‚Äúbig models‚Äù, frontier LLMs, are in a grey area
today. Legally, we don‚Äôt know, the courts haven‚Äôt ruled yet.
Extra-legally, it can feel like theft for sure. The vibes are mixed and
that is worth acknowledging. <strong>I don‚Äôt believe the law will
actually help us here.</strong> One reason is: the lawyers and the
judges who would adjudicate this are most likely using these tools. It
feels too much of a ‚Äúthe can of worms is already open‚Äù or ‚Äúthe egg is
already scrambled‚Äù situation. Extra-legally, pressure can always be
applied towards companies that they behave in a more ethical manner.
Sure. We should always strive for that. We don‚Äôt have to accept raw
capitalism. We are always making trade offs, and that will continue.</p>
</details>

<details>
<summary>Is the transformer pattern itself unethical?</summary>

<p>While I have read more than one person online trying to say it is, I
have found no reason to believe that it is.</p>
<p>Matrix transforms + a giant embedding space seems to be the main
magic here, and that‚Äôs math.</p>
<p>It helped me to learn more about what is actually going on. Checkout
these links:</p>
<ul>
<li><a
href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)">Transformer
on Wikipedia</a></li>
<li><a
href="https://www.youtube.com/watch?v=wjZofJX0v4M&amp;pp=ygUTMyBibHVlIHRyYW5zZm9ybWVycw%3D%3D">Transformers,
the tech behind LLMs | Deep Learning Chapter 5</a></li>
<li>üëâ <a href="https://www.youtube.com/watch?v=UZDiGooFs54">The moment
we stopped understanding AI: AlexNet</a></li>
</ul>
<p>If you watch only one explainer video, the <a
href="https://www.youtube.com/watch?v=UZDiGooFs54">AlexNext</a> one is
the best to really explain what is going on inside these things
<em>and</em> how we got to where we are today.</p>
</details>

<details>
<summary>Does AI break the economic model of the internet?</summary>

<p>The internet does not have one economic model. Advertising is
Google‚Äôs economic model (and then Facebook copied it as well). Saying
‚Äúadvertising is the economic model of the internet‚Äù benefits Google and
Facebook, it‚Äôs the story they want told. There are other economic models
working. Those will remain. Advertising may take a pretty big hit, for
sure.</p>
</details>

<details>
<summary>Is it really a good idea to give so much data to just a few very large companies?</summary>

<p>Definitely not.</p>
<p>And this is one reason I am working hard to enable local AI workflows
on phones and laptops. I want to make it easy to bend this tech to
benefit us, not bend ourselves to benefit it. It‚Äôs more important than
ever that we are in control of our data, of our context.</p>
</details>

<details>
<summary>Isn‚Äôt this all hype like web3?</summary>

<p>First, I hate that you made me type ‚Äúweb3‚Äù on this here website.</p>
<p>Second, web3 is a lot different. My coins get more valuable if you
buy a coin. It‚Äôs that simple. So I need as many people as possible to
buy coins, so I can buy low and sell high. Stable coins might have
utility, a lot of adjacent research and math is useful, IPFS is cool,
sure, but overall it really seems mostly like a way to make new
speculative assets.</p>
<p>AI is not like this at all. My AI tasks don‚Äôt start working better,
or become more valuable if you use AI too. Also, the companies are
losing money because of how expensive all of this is for them. If you
use AI right now, you are technically a burden to them. These AI
companies are ‚Äúvaluable‚Äù today because of future profits, not their
profits today. They have cash flowing through them, but most are not
capturing much of that cash‚Ä¶ instead they are spending money to watch
all their revenue flow out. The chip maker is doing quite well though,
if you haven‚Äôt seen.</p>
<p>So it‚Äôs just not the same. The parts that feel the same are probably
just general hype cycle dynamics.</p>
</details>

<details>
<summary>Isn‚Äôt this using so much water and energy that we should be concerned?</summary>

<p>Maybe.</p>
<p>It‚Äôs been difficult to find good reporting on this, and I just need
more time to look into it. This feels too important to ‚Äúhave a take
about‚Äù and not just take the time to do the research. So more
information TK here.</p>
<p>If you know, or just have some good links, then <a
href="https://indieweb.social/@myobie">hit me up on mastodon</a>.</p>
</details>

<h2 id="terms-and-definitions">Terms and definitions</h2>
<details>
<summary>Some people really don‚Äôt like calling it ‚ÄúAI,‚Äù because it‚Äôs not intelligent‚Ä¶</summary>

<p>Listen, I am still bitter about ‚Äúcloud computing.‚Äù</p>
<p>You are correct, it is not ‚Äúintelligent.‚Äù However, you can‚Äôt always
win the messaging wars. I‚Äôve moved on.</p>
<p>Related: <a
href="https://solarpunk.moe/@alilly/114928042375589900">https://solarpunk.moe/@alilly/114928042375589900</a></p>
</details>

<details>
<summary>What is an agent, what does that really mean?</summary>

<p>An agent is an LLM or SLM with possible tool/function calls, running
in a loop. The LM can generate a spec to call a tool, another program
calls that tool, then the previous conversation + the return value of
the tool is fed back into the LLM. Repeat. Sometimes there is a function
call to end the loop, the LM can generate the spec to call that to
finish the task.</p>
<p><strong>‚ÄùTools in a loop.‚Äù</strong></p>
<p>There are many other definitions of ‚Äúagent,‚Äù but <strong>this is the
one I like best right now.</strong></p>
<p>RE this article by Simon Willison: <a
href="https://simonwillison.net/2025/May/22/tools-in-a-loop/">Tools in a
Loop</a>.</p>
</details>

<h2 id="capabilities-today">Capabilities Today</h2>
<p><em>I have found it difficult to understand what AI tools can
actually do today. So I‚Äôve been using different AI tools in anger +
learning who to trust, who is reasonable about them. Here are some
answers to my questions about capabilities.</em></p>
<details>
<summary>AI tools aren‚Äôt _really_ doing anything beyond fancy spell check, next word prediction, right?</summary>

<p>Related: <a
href="https://mastodon.cloud/@jasongorman/114595098303670564">https://mastodon.cloud/@jasongorman/114595098303670564</a></p>
<p>It is more nuanced. Next word prediction is very important for these
products, but there are a few more things going on.</p>
<p>One thing that is worth watching is <a
href="https://www.youtube.com/watch?v=4NlrfOl0l8U">this video about
Google‚Äôs Alpha Geometry project</a> and how much ‚Äúnot AI‚Äù there is in
that system. You don‚Äôt need to understand all of the geometry to
understand that the AI part of the program isn‚Äôt even half of the whole
deal.</p>
<p>Another example is <a
href="https://www.uber.com/en-DE/blog/query-gpt/">QueryGPT</a>. A
specially trained LLM can generate SQL from a plain English query. Then
a normal database system will run the SQL and return the results. And,
if one wants, the return value from the database could be fed back onto
an LLM to generate a more ‚Äúhuman friendly‚Äù response.</p>
<p>Generative AI (different types of fancy prediction) output is very
useful as an input into another system. ChatGPT debuted as just
Generative AI without much else, it would spew back text to you and that
was it. But today, all of the major AI products are a series of
workflows and pipes, where one or more of the steps is generative.</p>
<p>So, yes and no.</p>
<p>And hopefully you can start to imagine how ‚Äúgenerating statistically
likely text / code to feed into something else‚Äù could be useful
sometimes.</p>
</details>

<details>
<summary>Are these AI tools good at/for search?</summary>

<p>Yes. Google search pretty much sucks right now.</p>
<p>AI research tools can be much better at surfacing the long tail. LLMs
themselves have nothing to do with search, but ‚ÄúAI tools‚Äù and ‚Äúagents‚Äù
which might use LLMs to generate search queries, filters, etc can do a
better job at searching than the average person. It feels to me like we
are just beginning to see how LLMs and SLMs can help us improve our
searching.</p>
<p>Related:</p>
<ul>
<li><a
href="https://steveklabnik.com/writing/i-am-disappointed-in-the-ai-discourse/">I
am disappointed in the AI discourse by Steve Klabnik</a></li>
<li><a href="https://github.com/assafelovic/gpt-researcher">Local Open
Source GPT Researcher</a></li>
</ul>
</details>

<details>
<summary>Why would I ask AI to research something for me? Won‚Äôt it just invent new things? When I ask AI to research something for me, what do I actually get?</summary>

<p>While working at Microsoft I heard a lot of <em>Bill Gates
stories.</em> üòÖ And while they might just be legends, one of them I
remember and is related.</p>
<p>It was said that when Bill needed to learn about some difficult
topic, he would pay a team to setup and video record lectures on the
topic at top Universities. That team would then synthesize those
recordings into a compressed curriculum for him, deliverable in a single
binder. Then he could review that and quickly become a pseudo expert.
And what a smart idea!</p>
<p>AI research tools can assemble a single folder of compressed
information for you today and this works well. And this is a new super
power. You can do what Bill Gates did (or maybe didn‚Äôt do, but was said
to have done).</p>
<p>Giving the LLM some research input and having it generate a
distillation or summary is where things might go wrong. It could
generate nonsense, sure. Having the folder of resources is the most
important part of the final artifact, not the generated ‚Äúhuman friendly‚Äù
summary.</p>
</details>

<details>
<summary>Can AI code as well as a human today?</summary>

<p>Yes.</p>
<p>In my experiments, it does as well as an average person. And I say
this confidently. I‚Äôve worked with enough programmers that I think you
could easily hit the average with today‚Äôs tools.</p>
<p>Now, to be clear, the average is a pretty low bar, so this isn‚Äôt as
exciting or damning as it might sound. Today‚Äôs AI coding tools seem
exactly like an unreliable coding intern who is in a hurry to go home.
Which I guess is an achievement for humankind. I do expect AI coding
tools to get much better over the next few years.</p>
<p>Code feels easier to accurately generate than normal language to me,
because of its limited grammar. And it can be tested to prove that it
works. So I think it‚Äôs about the loops of tools that go from generate to
test to remove, etc.</p>
<p>Related: <a
href="https://wandering.shop/@aesthr/114592630789058368">https://wandering.shop/@aesthr/114592630789058368</a></p>
<blockquote>
<p>Sadly, while there are a few studies flying around about coding
agents and their affect on productivity, there doesn‚Äôt appear to be any
<strong>reliable</strong> research yet about this to me. It‚Äôs just too
early to really know. I only ever see people posting links to studies
that validate their already held beliefs. Hopefully we‚Äôll see some peer
reviewed research about this in the next couple years.</p>
</blockquote>
</details>

<details>
<summary>Won‚Äôt these tools generate tons of bad, broken code?</summary>

<p>Yes.</p>
<p>Humans have done that for a while. Now robots will do it in a more
scalable way.</p>
<p>Related: <a
href="https://xoxo.zone/@microwavenby/114672517338884522">https://xoxo.zone/@microwavenby/114672517338884522</a></p>
<p>Also: <a
href="https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/">https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/</a></p>
<p>Also: <a
href="https://forum.cursor.com/t/cursor-yolo-deleted-everything-in-my-computer/103131">https://forum.cursor.com/t/cursor-yolo-deleted-everything-in-my-computer/103131</a></p>
<p>The most successful projects I‚Äôve worked on have been where I was
fixing some awful, existing code. So if you enjoy fixing broken
projects, this is your heyday.</p>
</details>

<details>
<summary>Can AI _design_, like posters, graphics, art today?</summary>

<p>Mostly no, from what I‚Äôve seen.</p>
<p><strong>You can design websites with AI tool,</strong> but that is
because that is coding. If you want a website that is as good as the
average website, then yeah, you can poop that out of an AI system
today.</p>
<p><strong>You can also generate bitmap images using AI tools,</strong>
but again that is not quite the same as ‚Äúdesign.‚Äù</p>
<p>Posters and graphic design are not code or bitmap images tho.</p>
<p><a
href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">Simon
Willison always has each new model generate a pelican riding a bicycle
and the results are informative.</a></p>
<p>It feels like someone is probably working on this right now and we‚Äôll
see something super surprising in the next couple years. Have you seen
things I haven‚Äôt, then please <a
href="https://indieweb.social/@myobie">hit me up on mastodon</a>.</p>
</details>

<details>
<summary>No one is making money off this stuff yet, right?</summary>

<p>Some are.</p>
<blockquote>
<p>Duolingo‚Äôs earnings are a window into the disconnect between the
vocal minority who complain about AI online and the value businesses
&amp; people are getting out of it‚Ä¶</p>
<p><a
href="https://mas.to/@carnage4life/114993379869191876">https://mas.to/@carnage4life/114993379869191876</a></p>
</blockquote>
<p>Also:</p>
<ul>
<li><a
href="https://www.businessinsider.com/ai-travel-agents-trip-planning-agency-business-growth-2025-8">Some
travel advisors are using AI to help plan trips and boost
business</a></li>
<li>‚Ä¶ more TK?</li>
</ul>
</details>

<h2 id="the-future">The Future</h2>
<details>
<summary>Will we even know if the remote coworkers we are chatting with are human or AI?</summary>

<p>Maybe not.</p>
<p>And yeah, that is dystopian. I am not excited about this, but if
current trends hold I don‚Äôt see how you can be 100% sure.</p>
<ul>
<li><a
href="https://www.wired.com/story/paranoia-social-engineering-real-fake/">Deepfakes,
Scams, and the Age of Paranoia</a></li>
<li>‚Ä¶TK</li>
</ul>
</details>

<details>
<summary>So, I won‚Äôt be writing copy / writing code in the future?</summary>

<p>I don‚Äôt think this is actually the right question. Many programmers
move into roles where they write less code and spend almost all their
time reviewing code. This is natural over time. And this could happen
with AI: code review instead of code gen for code experts. Copy editors
are the same: they are good at editing, someone else generates the
copy.</p>
<p>Also, photograph didn‚Äôt kill 100% of painting, but it definitely made
painting an extra special, rare thing. You can always keep painting, but
it might not be the dominant job anymore.</p>
</details>

<details>
<summary>Will my research, coding, writing, etc skills atrophy if I use AI?</summary>

<p>Seems possible.</p>
<p>It seems to me, if you are an expert, then you are less likely to
atrophy. If you are not an expert yet, and you don‚Äôt put in the effort,
then you are not building any ‚Äúmuscle.‚Äù This is true today: if another
human does the hard work for you, then you didn‚Äôt learn anything. And so
that seems likely to be true with AI.</p>
<blockquote>
<p>Sadly, while there are a few studies flying around, there doesn‚Äôt
appear to be any reliable research yet about this. It‚Äôs just too early
to really know. I only ever see people posting links to studies that
validate their already held beliefs. Hopefully we‚Äôll see some peer
reviewed research about this in the next couple years.</p>
</blockquote>
<p>If you are going to use AI, your best bet is probably to ask the AI
to help you become an expert, and not to just give you the answers.</p>
</details>

<details>
<summary>So, every product is going to have AI in it?</summary>

<p>Not every product.</p>
<p>Checkout <a
href="https://procreate.com/ai">https://procreate.com/ai</a>, for
example. My prediction is there will be a few apps that either
intentionally stay out of AI, or AI just never is a good fit for.</p>
</details>

<details>
<summary>So, every person is going to be use AI everyday?</summary>

<p>No, not everyone.</p>
<p>There definitely will be ‚ÄúAI vegans‚Äù and with diverse views about why
they are avoiding AI, just like there are diverse views about avoiding
meat.</p>
</details>

<details>
<summary>Couldn‚Äôt we just turn off all the servers and be done with all of this AI stuff?</summary>

<p>No.</p>
<p>There are very capable open source models, so you‚Äôd have to delete
code permanently from the universe, and we know that is impossible.</p>
<p>I mean, sure, every government could outlaw AI and the open source
models go underground. But this feels like a fantasy to me, and not
really worth considering further.</p>
</details>

<h2 id="vibes">Vibes</h2>
<details>
<summary>Won‚Äôt it feel not great to manage a bunch of robots, all of whom are bad in weirdly different ways at their jobs?</summary>

<p>Yes, it will not feel great for some people.</p>
<p>I am personally not excited to become a robot engineering manager‚Ä¶
and it definitely feels to me that that will be a job. I think the main
unknown is to what degree things will change. Will there be a few people
that change over to manage robots, or will the majority of knowledge
workers change over? If I had to guess today, I‚Äôd guess majority.</p>
<p>Related:</p>
<blockquote>
<p>The thing that keeps coming up as I talk to people about AI in their
workplaces is how <em>dehumanizing</em> it is. It's dehumanizing to ask
a machine to do something, and then have to correct it over and over;
it's dehumanizing to be told to read something that involved little to
no human effort to make.</p>
<p><a
href="https://mstdn.social/@aworkinglibrary/114659560902662745">https://mstdn.social/@aworkinglibrary/114659560902662745</a></p>
</blockquote>
</details>
        </div>
      </article>
    </main>
    <script async src="/assets/details-controls.js"></script>
    <script data-domain="nathanherald.com" defer src="https://stats.myobie.wtf/script.js"></script>
    <script async src="/transitions.js"></script>
</body>
</html>
