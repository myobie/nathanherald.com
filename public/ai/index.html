<!DOCTYPE html>
<html>
  <head lang="en-us">
    <meta charset="UTF-8">
    <title>
      I'm Nathan Herald ‚Üí This is not my take on AI
    </title>
    <script>
      if ((new URL(window.location.href)).host === 'myobie.com') { window.location.assign('https://nathanherald.com') }
    </script>
    <link href="https://cloud.typography.com/6836312/761366/css/fonts.css" rel="stylesheet" type="text/css">
    <link href="/styles.css" rel="stylesheet" type="text/css">
    <link href="/syntax-light.css" rel="stylesheet" type="text/css">
    <link href="/syntax-dark.css" rel="stylesheet" type="text/css">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta content="I'm Nathan Herald ‚Üí This is not my take on AI" name="title">
    <meta content="" name="description">
    <meta content="This is not my take on AI" property="og:title">
    <meta content="website" property="og:type">
    <meta content="" property="og:description">
    <meta content="/og.png" property="og:image">
    <meta content="I'm Nathan Herald" property="og:site_name">
    <link href="/rss.xml" rel="alternate" title="Feed of all the posts on nathanherald.com" type="application/rss+xml">
  </head>
  <body class="default">
    <header class="section-header">
      <div class="section-nav">
        <h1 class="home-link">
          <a class="never-underline" data-nospan="" href="/"><abbr title="Hello">üëã</abbr></a>
          <a href="/">I'm Nathan</a>
        </h1>
        <nav>
          <p>
            Find more in the <a href="/posts/">archive of all the posts on this site</a> or
            <a href="/rss.xml">subscribe with RSS</a>.
          </p>
        </nav>
      </div>
    </header>
    <main class="single">
      <article>
        <header>
          <h1>
            This is not my take on AI
          </h1>
        </header>
        <div class="content">
<p><em>The world doesn‚Äôt need another take.</em></p>
<p><em>TL;DR: I‚Äôve concluded that AI is coming and it‚Äôs important I
understand it and I am in control of my data, of my context. This is why
I am personally working to enable local AI workflows on phones and
laptops. I‚Äôll keep this page updated as I learn more.</em></p>
<hr />
<p><details-controls></details-controls></p>
<hr />
<p>AI tools and companies are progressing fast and I have a lot of
questions that I haven‚Äôt found easy answers to. <strong>So, I‚Äôve taken
some time to research, use AI for real work, and read a lot of takes on
AI. I‚Äôm collecting what I‚Äôve learned here.</strong> I plan to keep this
page semi-up-to-date over time as I learn more. I don‚Äôt want to make a
lot of blog posts about AI, instead I‚Äôll just have this page here as a
living document. I‚Äôll try to pull my ‚Äúbig takeaways‚Äù up here to the
top.</p>
<h2
id="big-takeaway-1-ai-is-here-and-its-best-for-me-to-understand-it">Big
Takeaway #1: AI is here and it‚Äôs best for me to understand it</h2>
<blockquote>
<iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen frameborder="0" height="315" src= "https://www.youtube-nocookie.com/embed/XAPfNPIvWkM" width="560"></iframe>

<p>Rage Against The Machine - Know Your Enemy Clip (Live At Finsbury
Park)</p>
</blockquote>
<p>This stuff is probably coming for you too. Those automated phone
systems where you ‚Äúhit 3 for billing‚Äù are terrible and annoying. They
are not <em>better</em> than just speaking to a human. And yet, those
are forced upon us to save costs, to reduce the number of jobs. AI seems
like that times 100: it will reduce costs so much that it will be used
whether it‚Äôs good or not.</p>
<p>And, if there are productivity gains to be had, and I think there
are, then we should own the means to run the programs that deliver them.
I‚Äôm building <a href="https://new.space/app">new.space</a> where you can
make sense of all your tabs, bookmarks, files, and notes in a private,
collaborative space using AI as you choose, you are in control. That is
one possible way to do own our data and context going forward: build
products that respect privacy and user control, letting us choose where
our data goes and when.</p>
<h2
id="big-takeaway-2-for-me-always-work-on-code-like-an-open-source-project">Big
takeaway #2 for me: Always work on code like an open source project</h2>
<p>I‚Äôve always tried to work as close to the open source model as
possible, and now I think that is even more important. In an open
project you get suggested code changes from people you‚Äôve never met or
heard of, their code is of dubious quality, and you have to really vet
and understand their code before accepting it into the project. Even
those you‚Äôve added as contributors can make mistakes or their accounts
can get hacked.</p>
<p>Code originating from generative AI must be seen as a suspicious
contribution as well.</p>
<p>What‚Äôs great is we already have tools to handle this. We have pull
request reviews, CI, multi-approval requirements before merging,
sandboxes or staging environments, etc. All of these things are made to
protect us from ourselves, and they will all help protect us from AI
tools as well.</p>
<p>TK I‚Äôd love to expand on this more soon.</p>
<h2 id="big-takeaway-3-the-lethal-trifecta-for-ai-agents">Big takeaway
#3: The lethal trifecta for AI agents</h2>
<p>Simon Willison identified the three properties that, when combined in
an AI agent system, create a serious security vulnerability:</p>
<ol type="1">
<li><strong>Access to private data</strong> (emails, files,
databases)</li>
<li><strong>Exposure to untrusted content</strong> (web pages, documents
from others)</li>
<li><strong>The ability to externally communicate</strong> (HTTP
requests, sending emails, etc.)</li>
</ol>
<blockquote>
<p>LLMs are unable to <em>reliably distinguish</em> the importance of
instructions based on where they came from.</p>
</blockquote>
<p>Removing any one of the three legs is enough to prevent the attack.
This is particularly relevant as people adopt <a
href="https://modelcontextprotocol.io/">MCP</a> plugins where mixing
tools from different sources can inadvertently assemble all three
dangerous ingredients together.</p>
<p>RE: <a
href="https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/">The
lethal trifecta for AI agents</a> by Simon Willison.</p>
<h2 id="the-internet-is-full-of-confusing-takes">The internet is full of
confusing takes</h2>
<p>Some of the smartest people I know are anti-AI and refuse to
knowingly use it. Some of the other smartest people I know are using AI
everyday, and say everyone else should too. I‚Äôve heard some say they‚Äôve
been ‚ÄúAI pilled‚Äù (both in a positive and negative way). Some say there
is no ethical way to use AI. Some say AI is mistaken so often to be
useless. Others say it‚Äôs correct so often that they don‚Äôt need as many
employees/coworkers anymore to do their work.</p>
<p>In this current moment, if someone tells you what AI can definitely
do or what it can definitely not do without a clear demo that you can
run yourself, then you can‚Äôt believe them. Companies are saying it can
do more than it probably can. Skeptics or those against AI are spreading
misinformation that it cannot do things which it can objectively do.
Both are problematic.</p>
<p>RE:</p>
<ul>
<li><a href="https://fly.io/blog/youre-all-nuts/">My AI Skeptic Friends
Are All Nuts</a></li>
<li><a
href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/?utm_source=chatgpt.com">Contra
Ptacek‚Äôs Terrible Article On AI</a></li>
<li><a href="https://mastodon.social/@jcoglan/114624176663492584">if you
are going to write an article making claims like AI can break down
problems, it can reason, it can refactor, it can help you learn, it is
genuinely capable at the task of producing software, you actually need
to provide evidence at this point</a></li>
</ul>
<details>
<summary>Some people really hate AI</summary>

<p>And I think it‚Äôs important to link to them here. These aren‚Äôt casual
skeptics ‚Äì they‚Äôve thought about it and concluded AI is fundamentally
harmful.</p>
<ul>
<li><a
href="https://malwaretech.com/2025/08/every-reason-why-i-hate-ai.html">Every
Reason Why I Hate AI and You Should Too</a> by Marcus Hutchins (the
security researcher who stopped WannaCry)</li>
<li><a
href="https://anthonymoser.github.io/writing/ai/haterdom/2025/08/26/i-am-an-ai-hater.html">I
Am An AI Hater</a> by Anthony Moser</li>
</ul>
<p>I mention further down that there will be ‚ÄúAI vegans.‚Äù These people
are already here and their concerns are worth reading even if you don‚Äôt
fully agree.</p>
</details>

<h2 id="ethical-concerns">Ethical concerns</h2>
<p>Two people I respect:</p>
<blockquote>
<p>‚Ä¶Ethical concerns front and center. First thing. Let‚Äôs get this out
of the way and then see if thre is anything left worth talking
about‚Ä¶</p>
<p><a
href="https://narrativ.es/@janl/114566975034056419">https://narrativ.es/@janl/114566975034056419</a></p>
</blockquote>
<p>and</p>
<blockquote>
<p>‚Ä¶If you refuse to use these tools on ethical grounds or simply don‚Äôt
bother to keep up with them, I fear your employment prospects are likely
to suffer in the short and medium term.</p>
<p><a
href="https://mastodon.social/@searls/114565915634957316">https://mastodon.social/@searls/114565915634957316</a></p>
</blockquote>
<p><em>So here are answers to my own ethical questions, front and
center. If you think of more, please hit me up <a
href="https://indieweb.social/@myobie">on mastodon</a>, I‚Äôd love to
learn/research more.</em></p>
<details>
<summary>Are all AI tools trained on stolen content?</summary>

<p>No. And this surprised me.</p>
<p>Firefly is trained only on licensed content by Adobe. This seems like
a great decision for them, especially from a quality control
perspective.</p>
<p><a
href="https://www.adobe.com/ai/overview/firefly/gen-ai-approach.html">Our
approach to generative AI with Adobe Firefly</a></p>
<blockquote>
<p>We only train Adobe Firefly on content where we have permission to do
so.</p>
</blockquote>
<p>Phi-4-mini claims to be trained on high quality data like licensed
books and academic sources. This is a very good, tool call capable model
that can run on a laptop or phone, so this opens up a ton of local AI
use cases where you use your own energy to do AI tasks with a more
ethically trained model.</p>
<p><a href="https://ollama.com/library/phi4-mini">phi-4-mini on
Ollama</a></p>
<blockquote>
<p>Phi-4-mini is a lightweight model built upon a blend of synthetic
datasets, data from filtered public domain websites, and acquired
academic books and Q&amp;A datasets. The goal of this approach was to
ensure that small capable models were trained with data focused on high
quality and advanced reasoning.</p>
</blockquote>
<p>So it seems very possible to build SMLs and maybe even LLMs in an
ethical way with enough effort and will.</p>
<p>However, all the ‚Äúbig models‚Äù, frontier LLMs, are in a grey area
today. Courts are now ruling, but in contradictory ways: the <a
href="https://www.ropesgray.com/en/insights/viewpoints/102lvxe/getty-image-loses-copyright-infringement-claim-against-stability-ai-in-uks-first">UK
High Court ruled</a> (Getty v. Stability AI, Nov 2025) that AI training
does NOT constitute copyright infringement because trained models don‚Äôt
‚Äústore‚Äù copyrighted works. Meanwhile, a <a
href="https://www.twobirds.com/en/insights/2025/landmark-ruling-of-the-munich-regional-court-(gema-v-openai)-on-copyright-and-ai-training">Munich
court ruled the opposite</a> (GEMA v. OpenAI, Nov 2025), finding OpenAI
violated German copyright law by training on song lyrics. In the US, the
<a
href="https://www.npr.org/2025/03/26/nx-s1-5288157/new-york-times-openai-copyright-case-goes-forward">NYT
v. OpenAI case</a> is progressing but hasn‚Äôt gone to trial yet. And the
music industry is <a
href="https://techcrunch.com/2025/11/25/warner-music-signs-deal-with-ai-music-startup-suno-settles-lawsuit/">settling
into licensing deals</a> rather than waiting for courts.</p>
<p>Extra-legally, it can feel like theft for sure. The vibes are mixed
and that is worth acknowledging. <strong>I don‚Äôt believe the law will
actually help us here.</strong> The egg is already scrambled and courts
across jurisdictions can‚Äôt even agree on the basics. Extra-legally,
pressure can always be applied towards companies that they behave in a
more ethical manner. Sure. We should always strive for that. We don‚Äôt
have to accept raw capitalism. We are always making trade offs, and that
will continue.</p>
</details>

<details>
<summary>Is the transformer pattern itself unethical?</summary>

<p>While I have read more than one person online trying to say it is, I
have found no reason to believe that it is.</p>
<p>Matrix transforms + a giant embedding space seems to be the main
magic here, and that‚Äôs math.</p>
<p>It helped me to learn more about what is actually going on. Checkout
these links:</p>
<ul>
<li><a
href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)">Transformer
on Wikipedia</a></li>
<li><a
href="https://www.youtube.com/watch?v=wjZofJX0v4M&amp;pp=ygUTMyBibHVlIHRyYW5zZm9ybWVycw%3D%3D">Transformers,
the tech behind LLMs | Deep Learning Chapter 5</a></li>
<li>üëâ <a href="https://www.youtube.com/watch?v=UZDiGooFs54">The moment
we stopped understanding AI: AlexNet</a></li>
</ul>
<p>If you watch only one explainer video, the <a
href="https://www.youtube.com/watch?v=UZDiGooFs54">AlexNet</a> one is
the best to really explain what is going on inside these things
<em>and</em> how we got to where we are today.</p>
</details>

<details>
<summary>Does AI break the economic model of the internet?</summary>

<p>The internet does not have one economic model. Advertising is
Google‚Äôs economic model (and then Facebook copied it as well). Saying
‚Äúadvertising is the economic model of the internet‚Äù benefits Google and
Facebook, it‚Äôs the story they want told. There are other economic models
working. Those will remain. Advertising may take a pretty big hit, for
sure.</p>
</details>

<details>
<summary>Is it really a good idea to give so much data to just a few very large companies?</summary>

<p>Definitely not.</p>
<p>And this is one reason I am working hard to enable local AI workflows
on phones and laptops. I want to make it easy to bend this tech to
benefit us, not bend ourselves to benefit it. It‚Äôs more important than
ever that we are in control of our data, of our context.</p>
</details>

<details>
<summary>Isn‚Äôt this all hype like web3?</summary>

<p>First, I hate that you made me type ‚Äúweb3‚Äù on this here website.</p>
<p>Second, web3 is a lot different. My coins get more valuable if you
buy a coin. It‚Äôs that simple. So I need as many people as possible to
buy coins, so I can buy low and sell high. Stable coins might have
utility, a lot of adjacent research and math is useful, IPFS is cool,
sure, but overall it really seems mostly like a way to make new
speculative assets.</p>
<p>AI is not like this at all. My AI tasks don‚Äôt start working better,
or become more valuable if you use AI too. Also, most of the big AI
companies are still losing money because of how expensive all of this is
for them, though there are exceptions ‚Äì Midjourney is profitable with
zero outside funding, and Microsoft is making real money on Azure AI.
Most AI companies are ‚Äúvaluable‚Äù today because of future profits, not
their profits today. They have cash flowing through them, but most are
not capturing much of that cash‚Ä¶ instead they are spending money to
watch all their revenue flow out. The chip maker is doing quite well
though, if you haven‚Äôt seen.</p>
<p>So it‚Äôs just not the same. The parts that feel the same are probably
just general hype cycle dynamics.</p>
</details>

<details>
<summary>Isn‚Äôt this using so much water and energy that we should be concerned?</summary>

<p>Yes, probably.</p>
<p>I‚Äôve read quite a bit about this now and the honest answer is: the
reporting doesn‚Äôt do a great job of putting things into perspective. A
single ChatGPT query uses roughly 5x more electricity than a web search,
but what does that actually mean compared to, say, the energy I use
making coffee or driving to the store? The articles I‚Äôve found are
better at describing the scale of data center growth than at helping a
normal person understand where AI fits into their own energy
footprint.</p>
<p>That said, the trajectory is concerning. <a
href="https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/">MIT
Technology Review reports</a> that by 2028 more than half of data center
electricity will go to AI, and no company reports AI-specific
environmental metrics. <a
href="https://www.brookings.edu/articles/ai-data-centers-and-water/">Brookings
reports</a> that a typical data center uses 300,000 gallons of water per
day for cooling, and large ones use 5 million gallons ‚Äì and water
cooling demand may increase 870%.</p>
<p>The real concern isn‚Äôt today‚Äôs usage but the growth trajectory. AI
usage is expected to double or triple in the next few years, and
infrastructure decisions being made now will lock in environmental
impacts for decades. Efficiency improvements are real (newer chips,
better cooling) but are being outpaced by demand growth.</p>
</details>

<h2 id="terms-and-definitions">Terms and definitions</h2>
<details>
<summary>Some people really don‚Äôt like calling it ‚ÄúAI,‚Äù because it‚Äôs not intelligent‚Ä¶</summary>

<p>Listen, I am still bitter about ‚Äúcloud computing.‚Äù</p>
<p>You are correct, it is not ‚Äúintelligent.‚Äù However, you can‚Äôt always
win the messaging wars. I‚Äôve moved on.</p>
<p>Related: <a
href="https://solarpunk.moe/@alilly/114928042375589900">https://solarpunk.moe/@alilly/114928042375589900</a></p>
</details>

<details>
<summary>What is an agent, what does that really mean?</summary>

<p>An agent is an LLM or SLM with possible tool/function calls, running
in a loop. The LM can generate a spec to call a tool, another program
calls that tool, then the previous conversation + the return value of
the tool is fed back into the LLM. Repeat. Sometimes there is a function
call to end the loop, the LM can generate the spec to call that to
finish the task.</p>
<p><strong>‚ÄùTools in a loop.‚Äù</strong></p>
<p>There are many other definitions of ‚Äúagent,‚Äù but <strong>this is the
one I like best right now.</strong></p>
<p>RE this article by Simon Willison: <a
href="https://simonwillison.net/2025/May/22/tools-in-a-loop/">Tools in a
Loop</a>.</p>
</details>

<h2 id="capabilities-today">Capabilities Today</h2>
<p><em>I have found it difficult to understand what AI tools can
actually do today. So I‚Äôve been using different AI tools in anger +
learning who to trust, who is reasonable about them. Here are some
answers to my questions about capabilities.</em></p>
<p>I have shipped code written by LLMs. Sometimes they write exactly the
code I would have written and it doesn‚Äôt need any touch ups. Other
times, they produce slop that I have to just clear and try again or
write myself. The variance is the thing ‚Äì it‚Äôs not consistently good or
consistently bad, it‚Äôs both, sometimes in the same session.</p>
<details>
<summary>AI tools aren‚Äôt _really_ doing anything beyond fancy spell check, next word prediction, right?</summary>

<p>Related: <a
href="https://mastodon.cloud/@jasongorman/114595098303670564">https://mastodon.cloud/@jasongorman/114595098303670564</a></p>
<p>It is more nuanced. Next word prediction is very important for these
products, but there are a few more things going on.</p>
<p>One thing that is worth watching is <a
href="https://www.youtube.com/watch?v=4NlrfOl0l8U">this video about
Google‚Äôs Alpha Geometry project</a> and how much ‚Äúnot AI‚Äù there is in
that system. You don‚Äôt need to understand all of the geometry to
understand that the AI part of the program isn‚Äôt even half of the whole
deal.</p>
<p>Another example is <a
href="https://www.uber.com/en-DE/blog/query-gpt/">QueryGPT</a>. A
specially trained LLM can generate SQL from a plain English query. Then
a normal database system will run the SQL and return the results. And,
if one wants, the return value from the database could be fed back onto
an LLM to generate a more ‚Äúhuman friendly‚Äù response.</p>
<p>Generative AI (different types of fancy prediction) output is very
useful as an input into another system. ChatGPT debuted as just
Generative AI without much else, it would spew back text to you and that
was it. But today, all of the major AI products are a series of
workflows and pipes, where one or more of the steps is generative.</p>
<p>So, yes and no.</p>
<p>And hopefully you can start to imagine how ‚Äúgenerating statistically
likely text / code to feed into something else‚Äù could be useful
sometimes.</p>
</details>

<details>
<summary>Are these AI tools good at/for search?</summary>

<p>Yes. Google search pretty much sucks right now.</p>
<p>AI research tools can be much better at surfacing the long tail. LLMs
themselves have nothing to do with search, but ‚ÄúAI tools‚Äù and ‚Äúagents‚Äù
which might use LLMs to generate search queries, filters, etc can do a
better job at searching than the average person. It feels to me like we
are just beginning to see how LLMs and SLMs can help us improve our
searching.</p>
<p>Related:</p>
<ul>
<li><a
href="https://steveklabnik.com/writing/i-am-disappointed-in-the-ai-discourse/">I
am disappointed in the AI discourse by Steve Klabnik</a></li>
<li><a href="https://github.com/assafelovic/gpt-researcher">Local Open
Source GPT Researcher</a></li>
</ul>
</details>

<details>
<summary>Why would I ask AI to research something for me? Won‚Äôt it just invent new things? When I ask AI to research something for me, what do I actually get?</summary>

<p>While working at Microsoft I heard a lot of <em>Bill Gates
stories.</em> üòÖ And while they might just be legends, one of them I
remember and is related.</p>
<p>It was said that when Bill needed to learn about some difficult
topic, he would pay a team to setup and video record lectures on the
topic at top Universities. That team would then synthesize those
recordings into a compressed curriculum for him, deliverable in a single
binder. Then he could review that and quickly become a pseudo expert.
And what a smart idea!</p>
<p>AI research tools can assemble a single folder of compressed
information for you today and this works well. And this is a new super
power. You can do what Bill Gates did (or maybe didn‚Äôt do, but was said
to have done).</p>
<p>Giving the LLM some research input and having it generate a
distillation or summary is where things might go wrong. It could
generate nonsense, sure. Having the folder of resources is the most
important part of the final artifact, not the generated ‚Äúhuman friendly‚Äù
summary.</p>
</details>

<details>
<summary>Can AI code as well as a human today?</summary>

<p>Yes.</p>
<p>In my experiments, it does as well as an average person. And I say
this confidently. I‚Äôve worked with enough programmers that I think you
could easily hit the average with today‚Äôs tools.</p>
<p>Now, to be clear, the average is a pretty low bar, so this isn‚Äôt as
exciting or damning as it might sound. Today‚Äôs AI coding tools seem
exactly like an unreliable coding intern who is in a hurry to go home.
Which I guess is an achievement for humankind. That said, every 3-6
months the quality and reliability of these tools really is increasing,
and I do expect them to keep getting better.</p>
<p>Code feels easier to accurately generate than normal language to me,
because of its limited grammar. And it can be tested to prove that it
works. So I think it‚Äôs about the loops of tools that go from generate to
test to remove, etc. Justin Searls has written that <a
href="https://justin.searls.co/posts/tdd-is-more-important-than-ever/">TDD
is more important than ever</a> precisely because AI coding agents need
verification to work well. He also <a
href="https://justin.searls.co/links/2025-09-08-i-ve-got-your-shovelware-right-here/">built
a project in three hours</a> that would have taken weeks, making it
worth doing at all.</p>
<p>There is real research now. A <a
href="https://mitsloan.mit.edu/ideas-made-to-matter/how-generative-ai-affects-highly-skilled-workers">large
RCT at Microsoft, Accenture, and a Fortune 100 company</a> (4,867
developers) found Copilot increased completed tasks by 26% ‚Äì but almost
all the gains went to junior devs (27-39%), while senior devs saw only
8-13%. Meanwhile, a <a
href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/">METR
study</a> of 16 experienced open-source developers found that AI users
were actually <strong>19% slower</strong> on their own repos ‚Äì and the
developers <em>believed</em> they were 20% faster. That
perception-reality gap is worth sitting with.</p>
<p>Related: <a
href="https://wandering.shop/@aesthr/114592630789058368">https://wandering.shop/@aesthr/114592630789058368</a></p>
<p>Also: <a
href="https://mastodon.social/@searls/115072539129871055">Sprinkling
Self-Doubt on ChatGPT</a> by Justin Searls.</p>
</details>

<details>
<summary>Won‚Äôt these tools generate tons of bad, broken code?</summary>

<p>Yes.</p>
<p>Humans have done that for a while. Now robots will do it in a more
scalable way.</p>
<p>Related: <a
href="https://xoxo.zone/@microwavenby/114672517338884522">https://xoxo.zone/@microwavenby/114672517338884522</a></p>
<p>Also: <a
href="https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/">https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/</a></p>
<p>Also: <a
href="https://forum.cursor.com/t/cursor-yolo-deleted-everything-in-my-computer/103131">https://forum.cursor.com/t/cursor-yolo-deleted-everything-in-my-computer/103131</a></p>
<p>The most successful projects I‚Äôve worked on have been where I was
fixing some awful, existing code. So if you enjoy fixing broken
projects, this is your heyday.</p>
</details>

<details>
<summary>Can AI _design_, like posters, graphics, art today?</summary>

<p>This needs to be split into two answers now.</p>
<p><strong>Reproducing something visually, pixel for pixel: mostly
no.</strong> Posters and graphic design are not code or bitmap images.
You can generate bitmap images using AI tools, but that is not quite the
same as ‚Äúdesign.‚Äù <a
href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">Simon
Willison always has each new model generate a pelican riding a bicycle
and the results are informative.</a></p>
<p><strong>Creating designs and working apps just by prompting: very
much yes.</strong> <a
href="https://blog.logrocket.com/ux-design/figma-make-review/">Figma
Make</a> can turn text prompts into working app prototypes and designs,
inheriting your existing design system, with no coding required. If you
want a website or app prototype that is as good as the average, then
yeah, you can get that from a prompt today.</p>
<p><strong>And you can now generate 3D models from text
prompts.</strong> Tools like <a href="https://www.meshy.ai/">Meshy</a>,
<a href="https://www.tripo3d.ai/">Tripo AI</a>, and Luma Genie can
generate textured, export-ready 3D meshes in 30-60 seconds from a
description. These cover modeling, texturing, retopology, and rigging.
(<a
href="https://www.3daistudio.com/3d-generator-ai-comparison-alternatives-guide/best-3d-generation-tools-2026/12-best-text-to-3d-tools-creators-2026">Comparison
of text-to-3D tools for 2026</a>)</p>
<p>This area is moving very fast.</p>
</details>

<details>
<summary>No one is making money off this stuff yet, right?</summary>

<p>Some are, with real numbers now.</p>
<p><a href="https://getlatka.com/companies/midjourney">Midjourney</a>
generated ~<span
class="math inline">500<em>M</em><em>i</em><em>n</em><em>r</em><em>e</em><em>v</em><em>e</em><em>n</em><em>u</em><em>e</em><em>i</em><em>n</em>2025<em>w</em><em>i</em><em>t</em><em>h</em><em>a</em><em>b</em><em>o</em><em>u</em><em>t</em>100<em>e</em><em>m</em><em>p</em><em>l</em><em>o</em><em>y</em><em>e</em><em>e</em><em>s</em><em>a</em><em>n</em><em>d</em>‚ÄÖ*‚ÄÖ*<em>z</em><em>e</em><em>r</em><em>o</em><em>o</em><em>u</em><em>t</em><em>s</em><em>i</em><em>d</em><em>e</em><em>f</em><em>u</em><em>n</em><em>d</em><em>i</em><em>n</em><em>g</em>‚ÄÖ*‚ÄÖ*‚ÄÖ‚àí‚ÄÖ‚àí<em>g</em><em>e</em><em>n</em><em>u</em><em>i</em><em>n</em><em>e</em><em>l</em><em>y</em><em>p</em><em>r</em><em>o</em><em>f</em><em>i</em><em>t</em><em>a</em><em>b</em><em>l</em><em>e</em>.[<em>O</em><em>p</em><em>e</em><em>n</em><em>A</em><em>I</em>](<em>h</em><em>t</em><em>t</em><em>p</em><em>s</em>‚ÄÑ:‚ÄÑ//<em>f</em><em>i</em><em>n</em><em>a</em><em>n</em><em>c</em><em>e</em>.<em>y</em><em>a</em><em>h</em><em>o</em><em>o</em>.<em>c</em><em>o</em><em>m</em>/<em>n</em><em>e</em><em>w</em><em>s</em>/<em>o</em><em>p</em><em>e</em><em>n</em><em>a</em><em>i</em>‚ÄÖ‚àí‚ÄÖ<em>c</em><em>f</em><em>o</em>‚ÄÖ‚àí‚ÄÖ<em>s</em><em>a</em><em>y</em><em>s</em>‚ÄÖ‚àí‚ÄÖ<em>a</em><em>n</em><em>n</em><em>u</em><em>a</em><em>l</em><em>i</em><em>z</em><em>e</em><em>d</em>‚ÄÖ‚àí‚ÄÖ<em>r</em><em>e</em><em>v</em><em>e</em><em>n</em><em>u</em><em>e</em>‚ÄÖ‚àí‚ÄÖ173519097.<em>h</em><em>t</em><em>m</em><em>l</em>)<em>h</em><em>i</em><em>t</em>¬†</span>20B
annualized revenue but is still burning ~$8B/year. <a
href="https://www.bloomberg.com/news/articles/2026-01-21/anthropic-s-revenue-run-rate-tops-9-billion-as-vcs-pile-in">Anthropic</a>
topped $9B run rate. <a
href="https://fortune.com/2025/12/11/cursor-ipo-1-billion-revenue-brainstorm-ai/">Cursor</a>
crossed $1B ARR but may be spending nearly 100% of revenue on API costs.
Microsoft Azure is growing 39% year-over-year, driven largely by AI.</p>
<p>So there is enormous revenue, but actual profitability among
pure-play AI companies is rare. Midjourney is the standout.</p>
<p>That said, a <a
href="https://mas.to/@carnage4life/115059290859727270">MIT NANDA
initiative study</a> found that 95% of generative AI deployments fail to
generate measurable business value. The money is flowing but the value
is concentrated.</p>
<blockquote>
<p>Duolingo‚Äôs earnings are a window into the disconnect between the
vocal minority who complain about AI online and the value businesses
&amp; people are getting out of it‚Ä¶</p>
<p><a
href="https://mas.to/@carnage4life/114993379869191876">https://mas.to/@carnage4life/114993379869191876</a></p>
</blockquote>
<p>Also: <a
href="https://www.businessinsider.com/ai-travel-agents-trip-planning-agency-business-growth-2025-8">Some
travel advisors are using AI to help plan trips and boost
business</a></p>
</details>

<h2 id="local-ai-tools-and-workflows">Local AI tools and workflows</h2>
<p><em>One of my big takeaways above is that we should own our data and
context. Here are some tools and projects that enable local AI
workflows.</em></p>
<ul>
<li><a href="https://github.com/tobi/qmd">qmd</a> by Tobi Lutke ‚Äì a
local search engine for your personal markdown files, notes, and
documents. BM25 + vector semantic search + LLM reranking, all running
locally. Has MCP server integration so you can plug it into Claude as a
context source.</li>
<li><a
href="https://nelson.cloud/local-text-summarization-with-ollama-and-python-is-just-string-manipulation/">Local
Text Summarization With Ollama and Python Is Just String
Manipulation</a> ‚Äì a practical tutorial showing that using local LLMs
through Ollama is fundamentally simple: you pass in a string, you get a
string back.</li>
<li><a
href="https://www.cohorte.co/blog/ollama-advanced-use-cases-and-integrations">Ollama
Advanced Use Cases and Integrations</a> ‚Äì structured outputs, tool
calling, RAG pipelines, all running locally.</li>
<li>I pushed my own <a
href="https://github.com/myobie/dot-files/commit/66816d0505b6466e5284a5e96c13aaaf1c791def">local
marketplace for Claude plugins</a> to my dot-files repo ‚Äì an extensible
framework for using Codex CLI as specialized agents within Claude for
code reviews, debugging, and refactoring.</li>
</ul>
<h2 id="people-building-with-ai-right-now">People building with AI right
now</h2>
<p>Mitchell Hashimoto (co-founder of HashiCorp) wrote <a
href="https://mitchellh.com/writing/my-ai-adoption-journey">My AI
Adoption Journey</a> documenting his six-phase path from skepticism to
running agents continuously. The whole thing is worth reading, but some
highlights: he forced himself to do every task twice (once manually,
then with an agent) to build real intuition. He dedicates the last 30
minutes of each workday to agent tasks. And he invests heavily in
‚Äúharness engineering‚Äù ‚Äì building verification tools and documentation
(<code>AGENTS.md</code>) that help agents self-correct. He also wrote
about <a href="https://mitchellh.com/writing/non-trivial-vibing">vibing
a non-trivial Ghostty feature</a> ‚Äì 16 AI sessions, $15.98 in tokens,
and about 8 hours across 3 days to ship a real feature. His core
takeaway: ‚ÄúGood AI drivers are experts in their domains and utilize AI
as an assistant, not a replacement.‚Äù</p>
<h2 id="openclaw">OpenClaw</h2>
<p><a href="https://openclaw.ai/">OpenClaw</a> (<a
href="https://github.com/openclaw/openclaw">github</a>) is an
open-source, self-hosted personal AI agent built by <a
href="https://steipete.me/">Peter Steinberger</a> (steipete, founder of
PSPDFKit). It‚Äôs an AI that doesn‚Äôt just chat but actually performs
tasks: messaging via WhatsApp/Telegram/Slack, browser control, device
automation, voice mode, and an extensible skills/plugin system. It runs
on your own hardware.</p>
<p>The project has had quite the naming saga: it started as
<strong>Clawdis</strong> (<a
href="https://github.com/steipete/clawdis">github</a>, Nov 2025), became
<strong>Clawdbot</strong> after growing to ~30k stars, then was renamed
to <strong>Moltbot</strong> after Anthropic‚Äôs legal team contacted
steipete about the name being too similar to ‚ÄúClaude‚Äù ‚Äì at which point
handle snipers grabbed the old social media accounts within seconds and
crypto scammers launched a fake $CLAWD token. It finally landed on
<strong>OpenClaw</strong> (Jan 2026) and now has 179k+ GitHub stars.</p>
<p>This project currently has all three legs of the <a
href="#big-takeaway-3-the-lethal-trifecta-for-ai-agents">lethal
trifecta</a>: access to private data, exposure to untrusted content, and
the ability to externally communicate. Worth keeping in mind.</p>
<p>Related:</p>
<ul>
<li><a href="https://steipete.me/posts/just-one-more-prompt">Just One
More Prompt</a> ‚Äì steipete reflects on his addiction to AI-powered
development, drawing parallels to unsustainable work patterns.</li>
<li><a
href="https://steipete.me/posts/2025/shipping-at-inference-speed">Shipping
at Inference-Speed</a> ‚Äì his development workflow with AI.</li>
</ul>
<h2 id="the-future">The Future</h2>
<details>
<summary>Will we even know if the remote coworkers we are chatting with are human or AI?</summary>

<p>Maybe not.</p>
<p>And yeah, that is dystopian. I am not excited about this, but if
current trends hold I don‚Äôt see how you can be 100% sure.</p>
<ul>
<li><a
href="https://www.wired.com/story/paranoia-social-engineering-real-fake/">Deepfakes,
Scams, and the Age of Paranoia</a></li>
</ul>
</details>

<details>
<summary>So, I won‚Äôt be writing copy / writing code in the future?</summary>

<p>I don‚Äôt think this is actually the right question. Many programmers
move into roles where they write less code and spend almost all their
time reviewing code. This is natural over time. And this could happen
with AI: code review instead of code gen for code experts. Copy editors
are the same: they are good at editing, someone else generates the
copy.</p>
<p>Also, photograph didn‚Äôt kill 100% of painting, but it definitely made
painting an extra special, rare thing. You can always keep painting, but
it might not be the dominant job anymore.</p>
</details>

<details>
<summary>Will my research, coding, writing, etc skills atrophy if I use AI?</summary>

<p>Seems likely.</p>
<p>It seems to me, if you are an expert, then you are less likely to
atrophy. If you are not an expert yet, and you don‚Äôt put in the effort,
then you are not building any ‚Äúmuscle.‚Äù This is true today: if another
human does the hard work for you, then you didn‚Äôt learn anything. And so
that seems likely to be true with AI.</p>
<p>There is now real research on this. An <a
href="https://www.anthropic.com/research/AI-assistance-coding-skills">Anthropic
study</a> (Jan 2026) had 52 junior engineers complete coding tasks with
and without AI. The AI group scored <strong>50% on a comprehension
quiz</strong> vs <strong>67% for the hand-coding group</strong> ‚Äì about
two letter grades lower. Debugging skills were hit hardest. And the time
savings from using AI were not even statistically significant. As they
put it: ‚ÄúAI-enhanced productivity is not a shortcut to competence.‚Äù</p>
<p>Meanwhile, a <a
href="https://digitaleconomy.stanford.edu/publications/canaries-in-the-coal-mine/">Stanford
study</a> found that employment for software devs aged 22-25 has
declined nearly 20% from its peak in late 2022. If juniors are being
hired less, the pipeline for developing senior talent narrows.</p>
<p>Related: <a
href="https://desunit.com/blog/in-the-long-run-llms-make-us-dumber/">In
the Long Run, LLMs Make Us Dumber</a> argues that over-reliance on LLMs
weakens cognitive abilities by removing beneficial mental friction.</p>
<p>If you are going to use AI, your best bet is probably to ask the AI
to help you become an expert, and not to just give you the answers.</p>
</details>

<details>
<summary>So, every product is going to have AI in it?</summary>

<p>Not every product.</p>
<p>Checkout <a
href="https://procreate.com/ai">https://procreate.com/ai</a>, for
example. My prediction is there will be a few apps that either
intentionally stay out of AI, or AI just never is a good fit for.</p>
<p>Meanwhile, some people are frustrated that AI is being added to
products they don‚Äôt want it in. <a
href="https://mastodon.social/@mcc/115176228086016550">One person is
considering blocking all browsers except Chrome</a> because it‚Äôs the
only major browser without built-in AI summarization.</p>
</details>

<details>
<summary>So, every person is going to be use AI everyday?</summary>

<p>No, not everyone.</p>
<p>There definitely will be ‚ÄúAI vegans‚Äù and with diverse views about why
they are avoiding AI, just like there are diverse views about avoiding
meat.</p>
</details>

<details>
<summary>Couldn‚Äôt we just turn off all the servers and be done with all of this AI stuff?</summary>

<p>No.</p>
<p>There are very capable open source models, so you‚Äôd have to delete
code permanently from the universe, and we know that is impossible.</p>
<p>I mean, sure, every government could outlaw AI and the open source
models go underground. But this feels like a fantasy to me, and not
really worth considering further.</p>
</details>

<h2 id="vibes">Vibes</h2>
<details>
<summary>Won‚Äôt it feel not great to manage a bunch of robots, all of whom are bad in weirdly different ways at their jobs?</summary>

<p>Yes, it will not feel great for some people.</p>
<p>I am personally not excited to become a robot engineering manager‚Ä¶
and it definitely feels to me that that will be a job. I think the main
unknown is to what degree things will change. Will there be a few people
that change over to manage robots, or will the majority of knowledge
workers change over? If I had to guess today, I‚Äôd guess majority.</p>
<p>Related:</p>
<blockquote>
<p>The thing that keeps coming up as I talk to people about AI in their
workplaces is how <em>dehumanizing</em> it is. It‚Äôs dehumanizing to ask
a machine to do something, and then have to correct it over and over;
it‚Äôs dehumanizing to be told to read something that involved little to
no human effort to make.</p>
<p><a
href="https://mstdn.social/@aworkinglibrary/114659560902662745">https://mstdn.social/@aworkinglibrary/114659560902662745</a></p>
</blockquote>
<p>Justin Searls wrote about <a
href="https://justin.searls.co/mails/2025-09/">The Generative Creativity
Spectrum</a>: when creativity‚Äôs value is internal (writing essays for
yourself), AI diminishes it. When it‚Äôs external (producing output for
others), AI can help. Programming sits uncomfortably in the middle ‚Äì AI
dramatically increases productivity but diminishes the engaging
problem-solving that made coding rewarding.</p>
<p>And steipete wrote about the flip side: AI can be <a
href="https://steipete.me/posts/just-one-more-prompt">addictive</a>.
‚ÄúJust one more prompt‚Äù mirrors unsustainable work patterns. AI restored
his passion for building but created a compulsive loop.</p>
</details>

<details>
<summary>The robots are faster than me now and I am the bottleneck</summary>

<p>AI agents can generate code and features so quickly that I may not
have time to actually try them out. I have a side project right now
where there is something waiting for me to test, to actually sit down
and use it, and I haven‚Äôt had time. The code was generated faster than I
can evaluate it. I am the bottleneck.</p>
<p>This is a weird inversion. The hard part used to be writing the code.
Now the hard part might be having enough hours in the day to verify,
test, and actually experience what was built.</p>
</details>
        </div>
      </article>
    </main>
    <script async src="/behavior.js"></script>
    <script async src="/assets/details-controls.js"></script>
    <script data-domain="nathanherald.com" defer src="https://stats.myobie.wtf/script.js"></script>
  </body>
</html>
